{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256c7a2b",
   "metadata": {},
   "source": [
    "# Task 5 : Credit Card Fraud Detection\n",
    "\n",
    "*Varad Deshmukh*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ca0e7",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* Build a machine learning model to identify fraudulent credit card transactions.\n",
    "* Preprocess and normalize the transaction data, handle class imbalance issues, and split the dataset into training and testing sets.\n",
    "* Train a classification algorithm, such as logistic regression or random forests, to classify transactions as fraudulent or genuine.\n",
    "* Evaluate the model's performance using metrics like precision, recall, and F1-score, and consider techniques like oversampling or undersampling for improving results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0abce3",
   "metadata": {},
   "source": [
    "> ## Importing Libraries\n",
    "\n",
    "In this project, along with the usual `NumPy` and `pandas`, we will need many modules from the `sklearn` library as well. To have an easier reference to the imported modules and classes and their usage at appropriate places, we will import them as they are required, and their rationale will be explained there itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80f4530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b33a019",
   "metadata": {},
   "source": [
    "> ## Loading the dataset\n",
    "\n",
    "The dataset for this project has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. We will be using the same data, with appropriate citations at the end.\n",
    "\n",
    "The data is in the form a '.csv' file named 'creditcard.csv', which contains about 2.85 lakh rows and 31 columns. The names of the columns, except three - Time, Amount and Class - have been changed into unidentifiable names owing to privacy and security concerns.\n",
    "\n",
    "This data has a column named 'Class', which is a categorical variable, showing whether the transaction was legitimate or fraud. The feature class has two values '0' and '1', for legitimate and fraud transactions, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca526ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset in the form of a pandas DataFrame\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# view first 5 rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9762c15e",
   "metadata": {},
   "source": [
    "> ## Data Preprocessing\n",
    "\n",
    "Data Preprocessing involves understanding the datatypes of the columns, checking for any missing values and subsequently cleaning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52a030a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# fetch information about the columns and their datatypes\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1418e",
   "metadata": {},
   "source": [
    "This shows that of all the 31 columns, only the 'Class' column is of data type 'int64', rest all are 'float64'. Moreover, the memory usage of the dataset is about 67.4 mb. Now we check for missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f80b961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedbde8",
   "metadata": {},
   "source": [
    "All the values being zero means that we have no missing values in our dataset. We now check whether the 'Class' column can be termed to be as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d73ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique values in the 'Class' column\n",
    "data['Class'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df3357",
   "metadata": {},
   "source": [
    "This shows that indeed the 'Class' column can be treated as a categorical, as it shows whether the transactions was legitimate or fraudulent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09131ba7",
   "metadata": {},
   "source": [
    "> ## Normalizing the data\n",
    "\n",
    "Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. In our case, our data includes both negative and positive quantities, both having wide ranges. It is often good choice to normalize data, as many machine learning algorithms have been found to run and converge faster when the data is normalized.\n",
    "\n",
    "So, for normaliing our data, we use the `MinMaxScaler()` class in the `scikit-learn` library for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94727b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MinMaxScaler() from scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9285d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "scaled = scaler.fit_transform(data)\n",
    "\n",
    "# make a pandas DataFrame out of the scaled data, to be used for further modelling\n",
    "scaled_data = pd.DataFrame(scaled, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6c5b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.766490</td>\n",
       "      <td>0.881365</td>\n",
       "      <td>0.313023</td>\n",
       "      <td>0.763439</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>0.266815</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.475312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561184</td>\n",
       "      <td>0.522992</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.391253</td>\n",
       "      <td>0.585122</td>\n",
       "      <td>0.394557</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978542</td>\n",
       "      <td>0.770067</td>\n",
       "      <td>0.840298</td>\n",
       "      <td>0.271796</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.262192</td>\n",
       "      <td>0.264875</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.480237</td>\n",
       "      <td>0.666938</td>\n",
       "      <td>0.336440</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.446013</td>\n",
       "      <td>0.416345</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.935217</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.868141</td>\n",
       "      <td>0.268766</td>\n",
       "      <td>0.762329</td>\n",
       "      <td>0.281122</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565477</td>\n",
       "      <td>0.546030</td>\n",
       "      <td>0.678939</td>\n",
       "      <td>0.289354</td>\n",
       "      <td>0.559515</td>\n",
       "      <td>0.402727</td>\n",
       "      <td>0.415489</td>\n",
       "      <td>0.311911</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.941878</td>\n",
       "      <td>0.765304</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.765647</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.789434</td>\n",
       "      <td>0.414999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559734</td>\n",
       "      <td>0.510277</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.223826</td>\n",
       "      <td>0.614245</td>\n",
       "      <td>0.389197</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.938617</td>\n",
       "      <td>0.776520</td>\n",
       "      <td>0.864251</td>\n",
       "      <td>0.269796</td>\n",
       "      <td>0.762975</td>\n",
       "      <td>0.263984</td>\n",
       "      <td>0.268968</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561327</td>\n",
       "      <td>0.547271</td>\n",
       "      <td>0.663392</td>\n",
       "      <td>0.401270</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>0.507497</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  0.000000  0.935192  0.766490  0.881365  0.313023  0.763439  0.267669   \n",
       "1  0.000000  0.978542  0.770067  0.840298  0.271796  0.766120  0.262192   \n",
       "2  0.000006  0.935217  0.753118  0.868141  0.268766  0.762329  0.281122   \n",
       "3  0.000006  0.941878  0.765304  0.868484  0.213661  0.765647  0.275559   \n",
       "4  0.000012  0.938617  0.776520  0.864251  0.269796  0.762975  0.263984   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.266815  0.786444  0.475312  ...  0.561184  0.522992  0.663793  0.391253   \n",
       "1  0.264875  0.786298  0.453981  ...  0.557840  0.480237  0.666938  0.336440   \n",
       "2  0.270177  0.788042  0.410603  ...  0.565477  0.546030  0.678939  0.289354   \n",
       "3  0.266803  0.789434  0.414999  ...  0.559734  0.510277  0.662607  0.223826   \n",
       "4  0.268968  0.782484  0.490950  ...  0.561327  0.547271  0.663392  0.401270   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.585122  0.394557  0.418976  0.312697  0.005824    0.0  \n",
       "1  0.587290  0.446013  0.416345  0.313423  0.000105    0.0  \n",
       "2  0.559515  0.402727  0.415489  0.311911  0.014739    0.0  \n",
       "3  0.614245  0.389197  0.417669  0.314371  0.004807    0.0  \n",
       "4  0.566343  0.507497  0.420561  0.317490  0.002724    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show how the scaled data looks like\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e13db",
   "metadata": {},
   "source": [
    "> ## Handling Class Imbalance Issues\n",
    "\n",
    "The Class Imbalance problem occurs when there is a severe skew in the class distribution of our training data. This skewness can influence the performance of our machine learning algorithms.\n",
    "\n",
    "I'll show what I mean to say. Let us group our data according to the value of 'Class' feature as 0 or 1. 0 means the transaction is legitimate and 1 means it is fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b71e6087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    284315\n",
       "1.0       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by 'Class' and find count\n",
    "scaled_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5e457",
   "metadata": {},
   "source": [
    "This shows that in our data, majority of transactions are legitimate and have the value of 'Class' feature as 0. Of the 2.85 lakh transactions, only 492 transactions are fraud. This imbalance in the class distribution of our training data may affect our machine learning algorithm because our algorithm may completely ignore the minority class. The reason this is an issue is because the minority class is often the class that we are most interested in. Here, the minority class is when 'Class' = 1, i.e. the transaction is fraudulent, precisely what we are interested in.\n",
    "\n",
    "So, to obviate this imbalance, we do Random Sampling. There are basically two types of random sampling - Oversampling and Undersampling. In oversampling, we duplicate samples from our minority class and in undersampling, we choose random entries from the majority class and delete the rest of them. Here, we choose undersampling.\n",
    "\n",
    "For that, we first separate the data into data for legitimate transactions and data for fraud transactions, using the 'Class' feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e446ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate legit and fraud transactions data\n",
    "legit_transactions = scaled_data[data['Class'] == 0]\n",
    "fraud_transactions = scaled_data[data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60cfa535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 31)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of legit transactions\n",
    "legit_transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c30608d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of fraud transactions\n",
    "fraud_transactions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358fc8c",
   "metadata": {},
   "source": [
    "Now, for performing the undersampling, we use the `RandomUnderSampler` class from the `imblearn` library, which is built for such imbalanced class problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b7a8bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5029e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the features (X) and target (y)\n",
    "X = scaled_data.drop(columns='Class', axis=1)\n",
    "y = scaled_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79ebb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the undersampler\n",
    "usampler = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24298b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling the features and target\n",
    "X_rus, y_rus = usampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfc67c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resultant undersampled feature matrix\n",
    "X_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb8e5561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resultant undersampled target\n",
    "y_rus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba51353",
   "metadata": {},
   "source": [
    "Thus, after undersampling, we see that the features matrix now has the same number of rows as that of target. This means, we will now train our data on the same number of legitimate and fraudulent transactions. Thus, we have eliminated the class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec3ffa",
   "metadata": {},
   "source": [
    "> ## Modelling the data\n",
    "\n",
    "We employ the Logistic Regression machine learning model, with the Limited-memory Broyden-Fletcher-Goldfarb-Shanno (LBFGS) algorithm, which is a popular optimization algorithm used in numerical optimization for this project. For splitting the data into training and testing data, we use the `train_test_split` and also import some important metrics that will give us an idea of how well our model is predicting the transaction legitimacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d8c90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary modules from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dad7ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test data for cross-validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus, test_size=0.2, random_state=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4af77e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes :\n",
      "X_train :  (787, 30)\n",
      "X_test :  (197, 30)\n",
      "y_train :  (787,)\n",
      "y_test :  (197,)\n"
     ]
    }
   ],
   "source": [
    "# how our training and test data look\n",
    "print('Shapes :')\n",
    "print('X_train : ', X_train.shape)\n",
    "print('X_test : ', X_test.shape)\n",
    "print('y_train : ', y_train.shape)\n",
    "print('y_test : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3b6c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model\n",
    "# specifiying number of iterations resolves the warnings\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f8ada0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model to our training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20f38d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data : 92.12%\n"
     ]
    }
   ],
   "source": [
    "# ascertaining the accuracy of predictions on our training data\n",
    "train_predictions = model.predict(X_train)\n",
    "training_accuracy = accuracy_score(train_predictions, y_train)\n",
    "print('Accuracy on training data : {:.2f}%'.format(training_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f26b0e",
   "metadata": {},
   "source": [
    "Having trained the model on our training data, we now ascertain its accuracy over our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd173ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data : 90.36%\n"
     ]
    }
   ],
   "source": [
    "# deploying the model on our test data and ascertaining its accuracy\n",
    "test_predictions = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(test_predictions, y_test)\n",
    "print('Accuracy on test data : {:.2f}%'.format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3f431",
   "metadata": {},
   "source": [
    "The Logistic Regression model that we deployed is 90.36% accurate in predicting whether a transaction was legit or fraud. This is a good amount of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a007a2e",
   "metadata": {},
   "source": [
    "> ## Metrics for our model\n",
    "\n",
    "We find the Precision, Recall and F1 Score for our model to ascertain its performance. We also find a classification report to summarize the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ea25ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 100.00%\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, test_predictions)\n",
    "print('precision : {:.2f}%'.format(precision * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b89bdf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall : 82.41%\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, test_predictions)\n",
    "print('recall : {:.2f}%'.format(recall * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e5714bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 : 90.36%\n"
     ]
    }
   ],
   "source": [
    "f1_score = f1_score(y_test, test_predictions)\n",
    "print('f1 : {:.2f}%'.format(f1_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00876733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      1.00      0.90        89\n",
      "         1.0       1.00      0.82      0.90       108\n",
      "\n",
      "    accuracy                           0.90       197\n",
      "   macro avg       0.91      0.91      0.90       197\n",
      "weighted avg       0.92      0.90      0.90       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a56e38",
   "metadata": {},
   "source": [
    "The model which we have built is now ready to be deployed. We have to feed in the features V1 to V28 to the model and it will predict whether the transaction is legitimate or fraudulent. Our model has been found to be around 90.36% accurate. There is more scope for improvisation, using more sphisticated machine learning algorithms and more elaborate random sampling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
